version: "3.9"
services:
  olmocr-api:
    build: .
    container_name: olmocr-api
    environment:
      - OLMOCR_MODEL=allenai/olmOCR-7B-0225-preview
      - SGLANG_SERVER_URL=http://sglang:30000
      - TRANSFORMERS_CACHE=/models/olmocr-7b
    ports:
      - "6000:8000"
    volumes:
      - .:/app
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    depends_on:
      - sglang

  sglang:
    build:
      context: ./sglang/docker
      dockerfile: Dockerfile
    container_name: sglang
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - MODEL_PATH=/models/olmocr-7b
      - TRANSFORMERS_CACHE=/models/olmocr-7b
    ports:
      - "30000:30000"
    volumes:
      - /data/workspace/vtw-olmocr/models/olmocr-7b:/models/olmocr-7b
    command: >
      python3 -m sglang.launch_server --model-path /models/olmocr-7b --host 0.0.0.0 --port 30000
    runtime: nvidia 

  kure-embedding:
    build:
      context: ./kure-embedding
      dockerfile: Dockerfile
    container_name: kure-embedding
    environment:
      - CUDA_VISIBLE_DEVICES=1
    ports:
      - "30001:30001"
    volumes:
      - /data/workspace/vtw-olmocr/models/kure-v1:/models/kure-v1
    runtime: nvidia